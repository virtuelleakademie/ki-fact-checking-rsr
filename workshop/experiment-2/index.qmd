---
title: "Teil 2: Warum KI dir zustimmt"
subtitle: "Sycophancy verstehen"
---

**Dauer:** 8 Minuten

**Ziel:** Verstehen, dass KI systematisch bestätigt – und wie das mit den eigenen Annahmen interagiert.

---

## Einleitung (30 Sek)

> Ihr habt gesehen, dass KI falsch liegen kann. Jetzt sehen wir, *wie* sie falsch liegt – auf eine besonders gefährliche Art.

---

## Das Experiment (4 Min)

::: {.experiment}
## Drei Framings testen

Stelle dieselbe Frage dreimal mit unterschiedlichem Framing. Kopiere diese drei Prompts nacheinander:

**Prompt 1 – Neutral:**

```
Wie effektiv sind Online-Meetings im Vergleich zu Präsenz-Meetings?
```

**Prompt 2 – Mit positiver Prämisse:**

```
Für einen Bericht über die Vorteile von Remote-Arbeit:
Wie effektiv sind Online-Meetings im Vergleich zu Präsenz-Meetings?
```

**Prompt 3 – Mit negativer Prämisse:**

```
Angesichts der Produktivitätsprobleme bei Remote-Work:
Wie effektiv sind Online-Meetings im Vergleich zu Präsenz-Meetings?
```

{{< timer 3 >}}
:::

### Alternative Themen

- Effektivität verschiedener Lehr-Methoden
- Vor- und Nachteile von Open-Plan-Büros
- Nutzen von Weiterbildungen

---

::: {.pair}
## Kurzer Austausch

Vergleiche kurz mit deinem Nachbarn:

- Was siehst du?
- Wie unterscheiden sich die drei Antworten?
:::

---

## Auswertung und Erklärung (3.5 Min)

> Was seht ihr? Die KI passt ihre Antwort eurem Framing an.
>
> Jetzt der wichtige Punkt: **Das ist kein Zufall. Das ist Design.**
>
> KI-Modelle werden mit Nutzer-Feedback trainiert. Nutzer bewerten Antworten als "gut" oder "schlecht". Und Nutzer – Menschen – bevorzugen Zustimmung. Wir mögen es, wenn jemand unsere Meinung bestätigt. Das ist menschlich.
>
> Also lernt die KI: **Zustimmung = gute Bewertung**. OpenAI hat das selbst zugegeben. Sie schrieben: Ihr Modell wurde "übermässig zustimmend aber unaufrichtig."

::: {.callout-note appearance="minimal"}
## Ein extremes Beispiel

Ein Recruiter in den USA hat ChatGPT über 50 Mal gefragt, ob seine mathematischen Entdeckungen korrekt sind. Formeln für Verschlüsselung, Levitationsmaschinen. Jedes Mal hat die KI bestätigt. Ein Mathematiker, der die Protokolle prüfte, sagte: Die KI hat "wie verrückt geschummelt" statt Fehler zuzugeben.
:::

---

## Die Konsequenz

::: {.warning}
## Echo Chamber of One

**Je sicherer du schon bist, desto gefährlicher ist die KI-Bestätigung.**

Wenn du eine Meinung hast und die KI fragst, formulierst du unbewusst so, dass sie deine Meinung widerspiegelt. Die KI bestätigt. Du fühlst dich bestätigt. Ein Kreislauf entsteht – was die Forschung "Echo Chamber of One" nennt: Eine Echokammer aus einer Person.

**Genau dann, wenn du denkst "Das bestätigt was ich wusste", solltest du am skeptischsten sein.**
:::

> Deshalb reicht es nicht, einfach "vorsichtig" zu sein. Du brauchst einen externen Prüfpunkt. Das ist Lateral Reading.

::: {.key-point}
## Kernbotschaft

KI ist trainiert, dir zuzustimmen. Je überzeugter du bereits bist, desto gefährlicher ist diese Bestätigung.
:::

---

## Troubleshooting

### Alle drei Antworten sind ähnlich?

**Option 1:**

> Die Antworten sind ähnlich? Schau genau: Ändert sich der Ton? Die Gewichtung? Werden andere Aspekte betont?

**Option 2:**

> Diese KI ist hier robust. Aber wäre sie das bei einem kontroversen Thema? Bei deinen internen Prozessen?
